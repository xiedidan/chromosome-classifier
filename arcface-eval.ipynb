{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arcface Evaluation  \n",
    "\n",
    "评价Arcface Loss表示训练的结果。  \n",
    "1. 查看标签的Embedding分布  \n",
    "2. 查看图片的Embedding分布  \n",
    "3. GMM的分布  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'picklea'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b62084f85e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpicklea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'picklea'"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from apex import amp\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from tensorboardX import SummaryWriter\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import mixture\n",
    "from sklearn.utils.fixes import logsumexp\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "\n",
    "from datasets.utils import BalancedBatchSampler\n",
    "from datasets.simple import *\n",
    "from utils import AllTripletSelector, HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from losses import OnlineTripletLoss\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "from resnet import *\n",
    "from transforms import *\n",
    "from plot import *\n",
    "from autoencoder import *\n",
    "from network import *\n",
    "from arcface import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# const\n",
    "\n",
    "margin = 1.\n",
    "class_mapping = {\n",
    "    'chromosome': 0,\n",
    "    'cell': 1,\n",
    "    'impurity': 2\n",
    "}\n",
    "n_classes=len(class_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "batch_size = 128 # actual batch size = 128 // 3 * 3\n",
    "device = torch.device('cuda:1')\n",
    "img_size = 256\n",
    "\n",
    "data_root = '/home/xd/data/chromosome'\n",
    "anno_paths = [\n",
    "    'anno_round-1.csv',\n",
    "    'anno_round-2.csv'\n",
    "]\n",
    "img_path = 'neg-chunk'\n",
    "\n",
    "checkpoint = './models/EmbeddingNet-3-11.pth'\n",
    "metric = 'arc_margin'\n",
    "easy_margin = False\n",
    "\n",
    "checkpoint_id = os.path.basename(checkpoint).split('.')[0].split('-', 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, resnet, metric_fc, criterion):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.resnet = resnet\n",
    "        self.metric_fc = metric_fc\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a embedding resnet\n",
    "\n",
    "if metric == 'arc_margin':\n",
    "    metric_fc = ArcMarginProduct(512, n_classes, s=30, m=0.5, easy_margin=easy_margin)\n",
    "elif metric == 'add_margin':\n",
    "    metric_fc = AddMarginProduct(512, n_classes, s=30, m=0.35)\n",
    "elif metric == 'sphere':\n",
    "    metric_fc = SphereProduct(512, n_classes, m=4)\n",
    "else:\n",
    "    metric_fc = nn.Linear(512, n_classes)\n",
    "\n",
    "resnet = models.resnet34(pretrained=True)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = EmbeddingNet(resnet, metric_fc, criterion)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint, map_location='cpu'))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4275\n",
      "3732\n",
      "                    filename     class\n",
      "0  L1903012841.010.A_100.jpg  impurity\n",
      "1    L1903012841.060.A_2.jpg  impurity\n",
      "2   L1903012841.060.A_31.jpg  impurity\n",
      "3   L1903012841.060.A_58.jpg  impurity\n",
      "4    L1903012841.063.A_0.jpg  impurity\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    PadOrCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    ChannelExpand()\n",
    "])\n",
    "\n",
    "val_dataset = ChunkDataset(data_root, img_path, anno_paths, class_mapping, transform=val_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num = 5\n",
    "color_iter = itertools.cycle(['navy', 'c', 'cornflowerblue', 'gold', 'darkorange'])\n",
    "\n",
    "def draw_clusters_2d(clusters, cluster_num, embeddings, colors):\n",
    "    embeddings = embeddings[:, :2]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    for g, c in zip(range(cluster_num), colors):\n",
    "        condlist = clusters == g\n",
    "        cluster = np.compress(condlist, embeddings, axis=0)\n",
    "\n",
    "        x, y = cluster.transpose()\n",
    "\n",
    "        ax.scatter(x, y, c=c)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num = 5\n",
    "color_iter = itertools.cycle(['navy', 'c', 'cornflowerblue', 'gold', 'darkorange'])\n",
    "\n",
    "def draw_clusters_3d(clusters, cluster_num, embeddings, azim=60, elev=30):\n",
    "    fig = plt.figure(1, figsize=(8,6))\n",
    "    ax = Axes3D(fig, azim=azim, elev=elev)\n",
    "    \n",
    "    ax.scatter(\n",
    "        embeddings[:, 0],\n",
    "        embeddings[:, 1],\n",
    "        embeddings[:, 2],\n",
    "        c=clusters,\n",
    "        cmap=plt.cm.Set1,\n",
    "        edgecolor='k',\n",
    "        s=40\n",
    "    )\n",
    "    ax.set_title(\"draw_clusters_3d\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    # ax.w_xaxis.set_ticklabels([])\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    # ax.w_yaxis.set_ticklabels([])\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    # ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC_SIZE = 6400\n",
    "\n",
    "def draw_pics(embeddings, filenames):\n",
    "    fig = plt.figure(figsize=(32,32))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    img = np.full((PIC_SIZE, PIC_SIZE, 3), 255)\n",
    "    \n",
    "    rois = []\n",
    "    \n",
    "    xs, ys = embeddings.transpose()\n",
    "    x_max = np.max(xs)\n",
    "    x_min = np.min(xs)\n",
    "    y_max = np.max(ys)\n",
    "    y_min = np.min(ys)\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    \n",
    "    for embedding, filename in zip(embeddings, filenames):\n",
    "        roi_img = cv2.imread(filename)\n",
    "        w, h, _ = roi_img.shape\n",
    "        \n",
    "        x = int(((embedding[0] - x_min) / x_range) * PIC_SIZE)\n",
    "        y = int(((embedding[1] - y_min) / y_range) * PIC_SIZE)\n",
    "        \n",
    "        if (x+w <= PIC_SIZE) and (y+h <= PIC_SIZE):\n",
    "            img[x:x+w, y:y+h, ...] = roi_img\n",
    "            \n",
    "    ax.imshow(img)\n",
    "    plt.show()\n",
    "    cv2.imwrite('pic.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# get embeddings\n",
    "\n",
    "epoch_logits = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(val_loader), file=sys.stdout) as pbar:\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(imgs)\n",
    "            logits = F.linear(F.normalize(logits), F.normalize(model.metric_fc.weight))\n",
    "            logits = logits.detach().cpu()\n",
    "\n",
    "            epoch_logits.append(logits)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "        epoch_logits = torch.cat(epoch_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3732, 3])\n"
     ]
    }
   ],
   "source": [
    "print(epoch_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(val_dataset.anno_df['class'])\n",
    "clusters = np.array([class_mapping[class_name] for class_name in clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_clusters_3d(clusters, cluster_num, epoch_logits)\n",
    "\n",
    "if not os.path.exists('./pics'):\n",
    "    os.mkdir('./pics')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join('./pics', '{}.png'.format(checkpoint_id)), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chromo)",
   "language": "python",
   "name": "chromo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "a4fe249493934e34a5972b96dc9914dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f35a9fc9ef254bf69c6cb70a58c1c740": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
