{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类器\n",
    "\n",
    "在用AutoEncoder预训练之后，Encoder已经可以对图像进行编码。这个时候是否可以回归到分类有监督学习？  \n",
    "有没有方法减少标注数量，做渐进式学习？  \n",
    "\n",
    "考虑如下分类：  \n",
    "1. 杂质  \n",
    "2. 血细胞  \n",
    "3. 染色体  \n",
    "\n",
    "这些分类是互斥的，使用Softmax激活。  \n",
    "对于混合样本，直接丢弃。  \n",
    "这里要利用Encoder+特征工程对少例分类（血细胞和杂质）进行挖掘，尽量使得分类标注比较均匀。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路一\n",
    "首先考虑锁定Encoder参数，只训练分类器，同时先标注简单样本，用BinaryCrossEntropy Loss函数，从而建立起最初的特征-分类映射，作为训练的Baseline。  \n",
    "\n",
    "此时网络在2个方面有所欠缺：  \n",
    "1. 对于难样本缺乏区分能力  \n",
    "2. Embedding本身的分布可能不够理想  \n",
    "\n",
    "进一步考虑利用Baseline模型，选取难样本进行标注。同时放开Encoder参数，利用Center或Margin Loss函数，训练的目标是改善Embedding分布，提升难样本的区分能力。  \n",
    "由于这个任务中，有些小染色体与杂质是比较像的，标注可能噪声较高，就不使用Focal Loss对难例进行加强训练。  \n",
    "\n",
    "如果顺利的话，此时应该就获得了比较理想的分类模型。  \n",
    "有没有办法进一步对Embedding进行监督，提高Embedding的分布质量？  \n",
    "有没有办法实现增强学习？  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路二\n",
    "\n",
    "考虑直接在Embedding上进行训练，即利用Triplet Margin Loss直接计算样本对的距离。  \n",
    "由于是多分类，3种分类就有9种样本对组合，需要尽量平均生成。  \n",
    "这样可以改善Embedding的分布。  \n",
    "\n",
    "猜测此时Embedding会呈现聚类效应，难例分布在概率密度较小的区域。  \n",
    "由于没有加入FC等回归器，需要在Embedding训练完成后，训练GMM等聚类模型，用于分类预测。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from tensorboardX import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "from datasets.simple import *\n",
    "from resnet import *\n",
    "from transforms import *\n",
    "from plot import *\n",
    "from autoencoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "device = torch.device('cuda:0')\n",
    "img_size = 256\n",
    "target_size = 256\n",
    "\n",
    "anno_paths = [\n",
    "    './cluster.csv'\n",
    "]\n",
    "\n",
    "data_root = '/mnt/nvme/data/chromosome/neg-chunk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet chunk dataset\n",
    "\n",
    "# paths are absolute!\n",
    "# support multiple anno paths (in csv), their lines are combined into one large anno dataframe\n",
    "# csv format: path, classNo\n",
    "\n",
    "class TripletChunkDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        anno_paths,\n",
    "        transform=None\n",
    "    ):\n",
    "        self.anno_paths = anno_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.anno_df = []\n",
    "        \n",
    "        for anno_path in self.anno_paths:\n",
    "            anno_df = pd.read_csv(anno_path)\n",
    "            self.anno_df.append(anno_df)\n",
    "        \n",
    "        self.anno_df = pd.concat(self.anno_df, axis=0)\n",
    "        print(self.anno_df.head())\n",
    "        self.total_len = len(self.anno_df)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # create triplet \n",
    "        anchor = self.anno_df.iloc[index]\n",
    "        anchor_class = self.anno_df.iloc[index, 1]\n",
    "\n",
    "        positive = self.anno_df[self.anno_df['classNo']==anchor_class].sample(n=1).iloc[0]\n",
    "        negative = self.anno_df[self.anno_df['classNo']!=anchor_class].sample(n=1).iloc[0]\n",
    "        \n",
    "        row_triplet = [anchor, positive, negative]\n",
    "        triplet = []\n",
    "        \n",
    "        for row in row_triplet:\n",
    "            row_path = row['path']\n",
    "            \n",
    "            filename = os.path.split(row_path)[1]\n",
    "            file_path = os.path.join(data_root, filename)\n",
    "            \n",
    "            row_img = Image.open(file_path)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                row_img = self.transform(row_img)\n",
    "                \n",
    "            triplet.append(row_img)\n",
    "        \n",
    "        return tuple(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path  classNo\n",
      "0  /media/ssd-ext4/neg-chunk/L1903042920.046.A_8.jpg        0\n",
      "1  /media/ssd-ext4/neg-chunk/L1903083406.078.A_11...        0\n",
      "2  /media/ssd-ext4/neg-chunk/L1903113536.040.A_16...        0\n",
      "3  /media/ssd-ext4/neg-chunk/L1903123563.277.A_35...        0\n",
      "4  /media/ssd-ext4/neg-chunk/L1903123702.038.A_17...        0\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    PadOrCrop(img_size),\n",
    "    transforms.RandomAffine(30, translate=(0.2, 0.2), resample=PIL.Image.BILINEAR, fillcolor=255),\n",
    "    transforms.ToTensor(),\n",
    "    ChannelExpand()\n",
    "])\n",
    "\n",
    "triplet_dataset = TripletChunkDataset(\n",
    "    anno_paths=anno_paths,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "triplet_loader = DataLoader(\n",
    "    triplet_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a embedding resnet\n",
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, resnet):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.resnet = resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "resnet = models.resnet34(pretrained=True)\n",
    "model = EmbeddingNet(resnet)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin=30.)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10\n",
      "100%|██████████| 260/260 [01:41<00:00,  2.56it/s]\n",
      "epoch: 2/10\n",
      "100%|██████████| 260/260 [01:40<00:00,  2.58it/s]\n",
      "epoch: 3/10\n",
      "100%|██████████| 260/260 [01:40<00:00,  2.60it/s]\n",
      "epoch: 4/10\n",
      "100%|██████████| 260/260 [01:40<00:00,  2.60it/s]\n",
      "epoch: 5/10\n",
      "100%|██████████| 260/260 [01:40<00:00,  2.60it/s]\n",
      "epoch: 6/10\n",
      "100%|██████████| 260/260 [01:39<00:00,  2.60it/s]\n",
      "epoch: 7/10\n",
      "100%|██████████| 260/260 [01:40<00:00,  2.60it/s]\n",
      "epoch: 8/10\n",
      "100%|██████████| 260/260 [01:39<00:00,  2.60it/s]\n",
      "epoch: 9/10\n",
      "100%|██████████| 260/260 [01:39<00:00,  2.60it/s]\n",
      "epoch: 10/10\n",
      "100%|██████████| 260/260 [01:39<00:00,  2.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "train_id = 1\n",
    "epoches = 10\n",
    "iter_count = len(triplet_loader)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    print('epoch: {}/{}'.format(epoch+1, epoches))\n",
    "    \n",
    "    with tqdm(total=iter_count, file=sys.stdout) as pbar:\n",
    "        for iter_no, triplet in enumerate(triplet_loader):\n",
    "            anchors, positives, negatives = triplet\n",
    "            \n",
    "            anchors = anchors.to(device)\n",
    "            positives = positives.to(device)\n",
    "            negatives = negatives.to(device)\n",
    "            \n",
    "            anchor_embeddings = model(anchors)\n",
    "            positive_embeddings = model(positives)\n",
    "            negative_embeddings = model(negatives)\n",
    "            \n",
    "            loss = criterion(\n",
    "                anchor_embeddings,\n",
    "                positive_embeddings,\n",
    "                negative_embeddings\n",
    "            )\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            writer.add_scalar(\n",
    "                'train/loss',\n",
    "                loss.item(),\n",
    "                epoch*iter_count+iter_no\n",
    "            )\n",
    "            \n",
    "            pbar.update(1)\n",
    "        \n",
    "        if not os.path.exists('./models'):\n",
    "            os.mkdir('./models')\n",
    "            \n",
    "        torch.save(model.state_dict(), './models/EmbeddingNet-{}-{}.pth'.format(train_id, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
